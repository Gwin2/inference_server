{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f2f4aa-ad88-4965-aaea-40a63b835bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x234ed57dc50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as v1\n",
    "from torchvision.io import read_image\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b3bbd2-3b13-4ecd-8353-bc08a7f0223a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 239/239 [00:00<00:00, 1326.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 512/512 [00:00<00:00, 1247.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 214/214 [00:00<00:00, 1388.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 798/798 [00:00<00:00, 1391.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 464/464 [00:00<00:00, 1379.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 226/226 [00:00<00:00, 1233.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 585/585 [00:00<00:00, 1408.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 383/383 [00:00<00:00, 1406.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 219/219 [00:00<00:00, 1350.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 244/244 [00:00<00:00, 1303.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 514/514 [00:00<00:00, 1414.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 237/237 [00:00<00:00, 1409.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 223/223 [00:00<00:00, 1410.22it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 526/526 [00:00<00:00, 1361.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 222/222 [00:00<00:00, 1312.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 532/532 [00:00<00:00, 1406.21it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 339/339 [00:00<00:00, 1388.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 218/218 [00:00<00:00, 1405.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 248/248 [00:00<00:00, 1407.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 224/224 [00:00<00:00, 1398.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 265/265 [00:00<00:00, 1408.40it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 302/302 [00:00<00:00, 1416.66it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 521/521 [00:00<00:00, 1345.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 496/496 [00:00<00:00, 1380.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 397/397 [00:00<00:00, 1391.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 508/508 [00:00<00:00, 1315.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 1382.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 287/287 [00:00<00:00, 1333.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 345/345 [00:00<00:00, 1346.54it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 224/224 [00:00<00:00, 1324.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 225/225 [00:00<00:00, 1215.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 211/211 [00:00<00:00, 1378.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11446, 2, 640, 1280)\n",
      "(11446,)\n"
     ]
    }
   ],
   "source": [
    "path = 'S:/drone_dataset_v4.0_pictures'\n",
    "dirnames = os.listdir(path)\n",
    "np.random.shuffle(dirnames)\n",
    "data = []\n",
    "labels = []\n",
    "num_classes = 1\n",
    "\n",
    "for dir in dirnames:\n",
    "    if dir.endswith('csv'):\n",
    "        continue\n",
    "    for file in tqdm(os.listdir(path+'/'+dir)):\n",
    "        data_file = np.asarray(np.load(path + '/' + dir + '/' + file, 'r+'))\n",
    "        data.append(data_file)\n",
    "        if 'drone' in list(file.split('_')):\n",
    "            labels.append(0.0)\n",
    "        if 'noise' in list(file.split('_')):\n",
    "            labels.append(0.5)\n",
    "        if 'wifi' in list(file.split('_')):\n",
    "            labels.append(1.0)\n",
    "\n",
    "data = np.asarray(data)\n",
    "labels = np.asarray(labels)\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876780e0-d4c0-4181-a323-632bfeae4ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlconfig in c:\\users\\admin\\.conda\\envs\\python310\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: omegaconf<3.0.0,>=2.3.0 in c:\\users\\admin\\.conda\\envs\\python310\\lib\\site-packages (from mlconfig) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\admin\\.conda\\envs\\python310\\lib\\site-packages (from omegaconf<3.0.0,>=2.3.0->mlconfig) (4.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\admin\\.conda\\envs\\python310\\lib\\site-packages (from omegaconf<3.0.0,>=2.3.0->mlconfig) (6.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d08c3856-c5d1-459e-b92d-c465376c938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os, shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlconfig\n",
    "from importlib import import_module\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def load_function(attr):\n",
    "    module_, func = attr.rsplit('.', maxsplit=1)\n",
    "    return getattr(import_module(module_), func)\n",
    "\n",
    "config = mlconfig.load('config_resnet18.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273ea28f-ae2e-4dd9-96e1-a5b7012df471",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "\n",
    "      self.X = X\n",
    "      self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x  = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a8d052-28fa-4824-99db-c0559c916058",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.24 GiB for an array with shape (3434, 2, 640, 1280) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m33\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_val))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#X_train = torch.tensor(X_train)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#X_val = torch.tensor(X_val)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#y_train = torch.tensor(y_train)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#y_val = torch.tensor(y_val)\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2640\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2636\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2638\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m-> 2640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2642\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[0;32m   2643\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2644\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2642\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2636\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m   2638\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2642\u001b[0m         (_safe_indexing(a, train), \u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:355\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32m~\\.conda\\envs\\python310\\lib\\site-packages\\sklearn\\utils\\__init__.py:184\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    183\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.24 GiB for an array with shape (3434, 2, 640, 1280) and data type uint8"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, random_state=33)\n",
    "print(len(y_val))\n",
    "#X_train = torch.tensor(X_train)\n",
    "#X_val = torch.tensor(X_val)\n",
    "#y_train = torch.tensor(y_train)\n",
    "#y_val = torch.tensor(y_val)\n",
    "train = MyDataset(X_train, y_train)\n",
    "val = MyDataset(X_val, y_val)\n",
    "\n",
    "#train = (torch.tensor(X_train), torch.tensor(y_train))\n",
    "#valid = (torch.tensor(X_val), torch.tensor(y_val))\n",
    "#train = torch.tensor(np.concatenate((X_train, y_train), axis=0))\n",
    "#valid = torch.tensor(np.concatenate((X_val, y_val), axis=0))\n",
    "\n",
    "batch_size = 3\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val, batch_size=batch_size)\n",
    "\n",
    "print(f\"Number of Train batches : {len(train_dl)}\\nNumber of Test batches : {len(val_dl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f6d12-b144-45b0-8a93-47374684332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_function(config.model.architecture)(pretrained=False)\n",
    "lin = model.conv1\n",
    "new_lin = nn.Sequential(\n",
    "    nn.Conv2d(2, 3, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "    lin\n",
    ")\n",
    "model.conv1 = new_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6339f3-93ba-47d4-ada5-6425876a21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.fc = torch.nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "import numpy as np\n",
    "import copy, timeit\n",
    "\n",
    "optimizer = load_function(config.optimizer.name)(model.parameters(), lr=config.optimizer.lr)\n",
    "criterion = load_function(config.loss_function.name)()\n",
    "scheduler = load_function(config.scheduler.name)(optimizer, step_size=config.scheduler.step_size, gamma=config.scheduler.gamma)\n",
    "\n",
    "if device!='cpu':\n",
    "    model = model.to(device)\n",
    "\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "epochs = 1\n",
    "\n",
    "best_acc = 0.0\n",
    "best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for epoch in range(1, epochs+1):\n",
    "        \n",
    "    print(f\"Epoch : {epoch}\\n\")\n",
    "    dataloader = None\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        batch_num = 0\n",
    "        \n",
    "        if phase == 'train' :\n",
    "            model.train()\n",
    "            dataloader = train_dl\n",
    "        else:\n",
    "            model.eval()\n",
    "            dataloader = val_dl\n",
    "\n",
    "        for (img, label) in dataloader:\n",
    "            #img = torch.unsqueeze(img,1)\n",
    "            label = torch.unsqueeze(label,1)\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                output = model(img)\n",
    "                _, pred = torch.max(output.data, 1)\n",
    "                #print(output.shape)\n",
    "                #print(output)\n",
    "                #print(label.shape)\n",
    "                #print(label)\n",
    "                loss = criterion(output, label)\n",
    "                #with torch.autocast('cuda'):\n",
    "                    #loss = criterion(torch.tensor(output).cuda(), torch.tensor(label).cuda())\n",
    "                if phase=='train' :\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            loss += loss.item() * img.size(0)\n",
    "            correct += torch.sum(pred == label.data)\n",
    "            total += batch_size\n",
    "            batch_num += 1\n",
    "            if batch_num % 50 == 0:\n",
    "                print(f\"Epoch : {epoch}\\t{phase} batch {batch_num} completed\")\n",
    "                \n",
    "        if phase=='train' :\n",
    "            train_loss.append(loss/len(train_dl))\n",
    "            train_acc.append(correct/total)\n",
    "            scheduler.step()\n",
    "            print(f'{phase} Loss: {train_loss[-1]:.4f}\\tAccuracy: {train_acc[-1]:.4f}')\n",
    "        else :\n",
    "            val_loss.append(loss/len(val_dl))\n",
    "            val_acc.append(correct/total)\n",
    "            print(f'{phase} Loss: {val_loss[-1]:.4f}\\tAccuracy: {val_acc[-1]:.4f}')\n",
    "\n",
    "            if val_acc[-1] > best_acc :\n",
    "                best_acc = val_acc[-1]\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "\n",
    "end = timeit.default_timer()\n",
    "print(f\"Total time elapsed = {end - start} seconds\")\n",
    "name = 'model.pth'\n",
    "model.load_state_dict(best_model)\n",
    "model = model.to('cpu')\n",
    "torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9cce90-abfc-4253-9443-820f12bbe016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
